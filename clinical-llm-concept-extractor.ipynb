{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import wandb\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sqlalchemy import create_engine, Column, Integer, String, JSON\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "# Initialize wandb\n",
    "wandb.init(project=\"clinical-llm-application\", name=\"concept-extraction-and-prediction\")\n",
    "\n",
    "# Connect to the source PostgreSQL database\n",
    "source_db_url = \"postgresql://username:password@localhost:5432/source_database\"\n",
    "source_engine = create_engine(source_db_url)\n",
    "\n",
    "# Create and connect to the local PostgreSQL database for model output\n",
    "local_db_url = \"postgresql://username:password@localhost:5432/local_model_output\"\n",
    "local_engine = create_engine(local_db_url)\n",
    "Base = declarative_base()\n",
    "\n",
    "class ModelOutput(Base):\n",
    "    __tablename__ = 'model_outputs'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    encounter_id = Column(String)\n",
    "    extracted_concepts = Column(JSON)\n",
    "    predicted_location = Column(String)\n",
    "\n",
    "Base.metadata.create_all(local_engine)\n",
    "Session = sessionmaker(bind=local_engine)\n",
    "local_session = Session()\n",
    "\n",
    "# Load the local LLM model\n",
    "model_name = \"path/to/your/local/llm/model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "def fetch_patient_data(encounter_id):\n",
    "    \"\"\"\n",
    "    Fetch patient data from the source database.\n",
    "    \"\"\"\n",
    "    with source_engine.connect() as connection:\n",
    "        result = connection.execute(f\"SELECT * FROM patient_encounters WHERE encounter_id = '{encounter_id}'\")\n",
    "        return result.fetchone()\n",
    "\n",
    "def extract_clinical_concepts(patient_data):\n",
    "    \"\"\"\n",
    "    Extract structured clinical concepts from unstructured patient data.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Extract clinical concepts from the following patient data:\n",
    "    {patient_data}\n",
    "    \n",
    "    Output the extracted concepts in JSON format.\n",
    "    \"\"\"\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_length=500)\n",
    "    extracted_concepts = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    try:\n",
    "        return json.loads(extracted_concepts)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error: Unable to parse extracted concepts as JSON.\")\n",
    "        return {}\n",
    "\n",
    "def predict_next_location(extracted_concepts):\n",
    "    \"\"\"\n",
    "    Predict the next location for the patient encounter based on extracted concepts.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Given the following extracted clinical concepts:\n",
    "    {json.dumps(extracted_concepts, indent=2)}\n",
    "    \n",
    "    Predict the most likely next location for this patient encounter.\n",
    "    \"\"\"\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_length=50)\n",
    "    predicted_location = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    return predicted_location.strip()\n",
    "\n",
    "def process_encounter(encounter_id):\n",
    "    \"\"\"\n",
    "    Process a single patient encounter.\n",
    "    \"\"\"\n",
    "    patient_data = fetch_patient_data(encounter_id)\n",
    "    extracted_concepts = extract_clinical_concepts(patient_data)\n",
    "    predicted_location = predict_next_location(extracted_concepts)\n",
    "    \n",
    "    # Log to wandb\n",
    "    wandb.log({\n",
    "        \"encounter_id\": encounter_id,\n",
    "        \"num_extracted_concepts\": len(extracted_concepts),\n",
    "        \"predicted_location\": predicted_location\n",
    "    })\n",
    "    \n",
    "    # Store results in local database\n",
    "    model_output = ModelOutput(\n",
    "        encounter_id=encounter_id,\n",
    "        extracted_concepts=extracted_concepts,\n",
    "        predicted_location=predicted_location\n",
    "    )\n",
    "    local_session.add(model_output)\n",
    "    local_session.commit()\n",
    "    \n",
    "    return extracted_concepts, predicted_location\n",
    "\n",
    "def analyze_results():\n",
    "    \"\"\"\n",
    "    Analyze and visualize the results.\n",
    "    \"\"\"\n",
    "    results = local_session.query(ModelOutput).all()\n",
    "    \n",
    "    # Calculate some statistics\n",
    "    num_encounters = len(results)\n",
    "    avg_concepts_per_encounter = np.mean([len(r.extracted_concepts) for r in results])\n",
    "    location_distribution = {}\n",
    "    for r in results:\n",
    "        location_distribution[r.predicted_location] = location_distribution.get(r.predicted_location, 0) + 1\n",
    "    \n",
    "    # Create a bar plot of predicted locations\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(location_distribution.keys(), location_distribution.values())\n",
    "    plt.title(\"Distribution of Predicted Next Locations\")\n",
    "    plt.xlabel(\"Location\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Log plot to wandb\n",
    "    wandb.log({\"location_distribution\": wandb.Image(plt)})\n",
    "    \n",
    "    # Log statistics to wandb\n",
    "    wandb.log({\n",
    "        \"num_encounters\": num_encounters,\n",
    "        \"avg_concepts_per_encounter\": avg_concepts_per_encounter\n",
    "    })\n",
    "    \n",
    "\n",
    "# Example usage (you can put this in a separate cell for execution)\n",
    "encounter_ids = [\"1\", \"2\", \"3\", ...]  \n",
    "for encounter_id in encounter_ids:\n",
    "    extracted_concepts, predicted_location = process_encounter(encounter_id)\n",
    "    print(f\"Processed encounter {encounter_id}\")\n",
    "    print(f\"Extracted concepts: {json.dumps(extracted_concepts, indent=2)}\")\n",
    "    print(f\"Predicted next location: {predicted_location}\")\n",
    "    print(\"---\")\n",
    "\n",
    "# Analyze results (you can put this in a separate cell for execution)\n",
    "analyze_results()\n",
    "\n",
    "# Close wandb run (you can put this in a final cell for execution)\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
